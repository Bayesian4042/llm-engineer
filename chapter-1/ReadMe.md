1. Before openai introduced chatgpt, it was difficult to run language models for mainly two reasons. First, it was difficult to run LLMs due to high hardware requirements and second, if you don't have ML/DL experience it is impossible for you to run anything.

2. Now, it is very easy to consume any LLM models through an API like gpt-4o-mini or run it locally. There are two types of models, one is propretirt models and other are open source models.

3. Open source models are free to download their weight and use it for you own use case. There are great places to find these open source models like Hugging Face Hub or through CLI with Ollama.

4. propretirty models are easy to consume through APIs and state of the art models like OpenAI, Anthropic, Cohere, Google.

5. In this chapter, we will implement, how to consume LLM using an api for our use case.